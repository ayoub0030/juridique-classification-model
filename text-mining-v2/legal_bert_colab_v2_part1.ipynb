{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal Document Classification with BERT - V2 (Full Dataset)\n",
    "\n",
    "This notebook demonstrates how to build a BERT-based classifier for legal documents using the full 45K dataset with complete document text (header + recitals + main body).\n",
    "\n",
    "## Part 1: Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch scikit-learn tqdm matplotlib seaborn pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive for saving models and data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create a folder for the project\n",
    "!mkdir -p /content/drive/MyDrive/legal_bert_classification_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Print GPU info if available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Upload\n",
    "\n",
    "This section lets you upload the full 45K dataset that was processed with the `process_full_dataset.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Option 1: Upload the dataset directly\n",
    "from google.colab import files\n",
    "\n",
    "# You can upload the full dataset CSV here\n",
    "print(\"Upload your full_bert_dataset.csv file:\")\n",
    "uploaded = files.upload()  # Will prompt for file upload\n",
    "\n",
    "# Get the uploaded file name\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Uploaded {filename} successfully!\")\n",
    "    \n",
    "    # Save to Drive for future use\n",
    "    with open(f\"/content/drive/MyDrive/legal_bert_classification_v2/{filename}\", 'wb') as f:\n",
    "        f.write(uploaded[filename])\n",
    "    print(f\"Saved to Drive for future reference\")\n",
    "    \n",
    "    # Read the uploaded CSV\n",
    "    df = pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')))\n",
    "    print(f\"Dataset loaded with {len(df)} rows and {df.columns.tolist()} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Option 2: If you've already uploaded to Drive, set the path\n",
    "# dataset_path = '/content/drive/MyDrive/legal_bert_classification_v2/full_bert_dataset.csv'\n",
    "# df = pd.read_csv(dataset_path)\n",
    "# print(f\"Dataset loaded from Drive with {len(df)} rows and {df.columns.tolist()} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic verification that the data looks correct\n",
    "# Display first few rows\n",
    "print(\"First 3 rows of the dataset:\")\n",
    "print(df.head(3))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Verify label distribution\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Legal Document Classification with BERT - V2 Part 1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
