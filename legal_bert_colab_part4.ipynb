{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal Document Classification with BERT\n",
    "\n",
    "## Part 7: Model Training Execution\n",
    "\n",
    "Initialize and train the BERT model on our legal document dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load pre-trained model\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "print(\"Loading pre-trained BERT model...\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',  # Change to 'nlpaueb/legal-bert-base-uncased' for legal BERT\n",
    "    num_labels=len(label_encoder.classes_),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set training parameters\n",
    "epochs = 4  # You can try more epochs if needed\n",
    "learning_rate = 2e-5\n",
    "warmup_steps = 0\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Create save directory if it doesn't exist\n",
    "import os\n",
    "save_dir = '/content/drive/MyDrive/legal_bert_classification'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "trained_model, history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    device, \n",
    "    epochs=epochs, \n",
    "    learning_rate=learning_rate, \n",
    "    warmup_steps=warmup_steps, \n",
    "    weight_decay=weight_decay,\n",
    "    save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the final model\n",
    "model_save_path = os.path.join(save_dir, 'final_model')\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Final model saved to {model_save_path}\")\n",
    "\n",
    "# Save training history\n",
    "import pickle\n",
    "with open(os.path.join(save_dir, 'training_history.pkl'), 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses'], label='Train Loss')\n",
    "plt.plot(history['val_losses'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_accuracies'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, 'training_history.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Model Evaluation\n",
    "\n",
    "Evaluate the trained model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate final model\n",
    "def evaluate_model(model, dataloader, device, label_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=label_names, digits=4)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return all_preds, all_labels, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, 'best_model.pt')))\n",
    "model.to(device)\n",
    "\n",
    "# Run evaluation\n",
    "predictions, true_labels, report, cm = evaluate_model(\n",
    "    model, val_loader, device, label_encoder.classes_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, 'confusion_matrix.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate per-class accuracy\n",
    "class_accuracy = {}\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    class_mask = [tl == i for tl in true_labels]\n",
    "    class_true = sum(class_mask)\n",
    "    class_correct = sum(1 for p, tl in zip(predictions, true_labels) if p == tl and tl == i)\n",
    "    class_accuracy[label] = class_correct / class_true if class_true > 0 else 0\n",
    "\n",
    "# Plot per-class accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(class_accuracy.keys()), y=list(class_accuracy.values()))\n",
    "plt.title('Accuracy by Document Type')\n",
    "plt.xlabel('Document Type')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "for i, val in enumerate(class_accuracy.values()):\n",
    "    plt.text(i, val + 0.01, f'{val:.4f}', ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, 'class_accuracy.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Inference with New Data\n",
    "\n",
    "Create functions to use the trained model for classifying new legal documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_document_type(text, model, tokenizer, label_encoder, device, max_length=512):\n",
    "    \"\"\"Predict document type for a new text.\"\"\"\n",
    "    # Prepare the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Get predicted class\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    confidence, predicted_class = torch.max(probabilities, dim=1)\n",
    "    \n",
    "    # Convert to label\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class.item()])[0]\n",
    "    \n",
    "    return {\n",
    "        'predicted_label': predicted_label,\n",
    "        'confidence': confidence.item(),\n",
    "        'probabilities': {\n",
    "            label: prob.item() \n",
    "            for label, prob in zip(label_encoder.classes_, probabilities[0].cpu().numpy())\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example usage\n",
    "sample_text = \"\"\"REGULATION (EU) 2016/679 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\n",
    "of 27 April 2016\n",
    "on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)\n",
    "(Text with EEA relevance)\n",
    "THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,\n",
    "Having regard to the Treaty on the Functioning of the European Union, and in particular Article 16 thereof,\n",
    "Having regard to the proposal from the European Commission,\n",
    "After transmission of the draft legislative act to the national parliaments,\n",
    "Having regard to the opinion of the European Economic and Social Committee,\n",
    "Having regard to the opinion of the Committee of the Regions,\n",
    "Acting in accordance with the ordinary legislative procedure,\"\"\"\n",
    "\n",
    "# Make prediction\n",
    "prediction = predict_document_type(sample_text, model, tokenizer, label_encoder, device)\n",
    "\n",
    "# Print results\n",
    "print(f\"Predicted document type: {prediction['predicted_label']}\")\n",
    "print(f\"Confidence: {prediction['confidence']:.4f}\")\n",
    "print(\"\\nProbability for each class:\")\n",
    "for label, prob in prediction['probabilities'].items():\n",
    "    print(f\"  {label}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Save and Load the Model\n",
    "\n",
    "Instructions for saving and loading the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model and tokenizer\n",
    "# This was already done in the training section, but here's the code again:\n",
    "model_save_path = os.path.join(save_dir, 'final_model')\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Final model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example of how to load the model later\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import pickle\n",
    "\n",
    "def load_model_for_inference():\n",
    "    # Load label encoder\n",
    "    with open('/content/drive/MyDrive/legal_bert_classification/label_encoder.pkl', 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model_path = '/content/drive/MyDrive/legal_bert_classification/final_model'\n",
    "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    return model, tokenizer, label_encoder, device\n",
    "\n",
    "# Uncommment to test loading and using the model\n",
    "# loaded_model, loaded_tokenizer, loaded_encoder, loaded_device = load_model_for_inference()\n",
    "# prediction = predict_document_type(\"Your text here\", loaded_model, loaded_tokenizer, loaded_encoder, loaded_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Previous Approach\n",
    "\n",
    "Finally, let's compare the BERT-based approach with the previous concept-code-based approach:\n",
    "\n",
    "1. **Data Source**:\n",
    "   - Previous: Used concept codes (e.g., \"1086, 1196, 2002\")\n",
    "   - BERT: Uses header + recitals text\n",
    "\n",
    "2. **Model Complexity**:\n",
    "   - Previous: Simple bag-of-words with LogisticRegression\n",
    "   - BERT: Deep transformer model with millions of parameters\n",
    "\n",
    "3. **Resource Requirements**:\n",
    "   - Previous: Low (can run on CPU)\n",
    "   - BERT: High (requires GPU for efficient training)\n",
    "\n",
    "4. **Performance**:\n",
    "   - Previous: 91.18% accuracy\n",
    "   - BERT: Potentially higher accuracy, especially for documents with similar concepts but different legal purposes\n",
    "\n",
    "5. **Language Understanding**:\n",
    "   - Previous: No understanding of the legal text\n",
    "   - BERT: Can understand legal language patterns and context\n",
    "\n",
    "Both approaches have their strengths - the concept-based model is simple and efficient, while the BERT model has the potential for deeper understanding of legal texts."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Legal Document Classification with BERT - Part 4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
